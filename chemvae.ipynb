{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating VAE in keras to generate molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense, LSTM, Lambda, Reshape, TimeDistributed, Convolution1D, Flatten, GRU\n",
    "from keras.models import Model\n",
    "from keras import objectives\n",
    "from keras.layers.core import RepeatVector\n",
    "from keras.losses import MSE\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, History\n",
    "\n",
    "with open('smiles.txt') as f:\n",
    "    full_smiles_as_list = f.readlines()\n",
    "    \n",
    "SMILES_CHARS = set()\n",
    "for smile in full_smiles_as_list:\n",
    "    set_smile = set(smile)\n",
    "    SMILES_CHARS = SMILES_CHARS.union(set_smile)\n",
    "\n",
    "SMILES_CHARS = list(SMILES_CHARS)\n",
    "SMILES_CHARS.insert(0,' ')\n",
    "SMILES_CHARS.insert(1,'!')\n",
    "\n",
    "max_smiles_len = 100\n",
    "num_smiles_chars =  len(SMILES_CHARS)\n",
    "\n",
    "input_dim = (max_smiles_len, num_smiles_chars)\n",
    "output_dim = (max_smiles_len, num_smiles_chars)\n",
    "\n",
    "\n",
    "smi2index = dict((c, i) for i, c in enumerate(SMILES_CHARS))\n",
    "index2smi = dict((i, c) for i, c in enumerate(SMILES_CHARS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "smi2index['\\n'] = smi2index[' ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 292\n",
    "inter_dim = 488"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "tf.random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smiles_to_onehot(smiles, max_len = max_smiles_len):\n",
    "    onehot = np.zeros((max_len, len(SMILES_CHARS)))\n",
    "    onehot[0, smi2index['!']] = 1\n",
    "    for i, c in enumerate(smiles):\n",
    "        onehot[i+1, smi2index[c]] = 1\n",
    "    return onehot\n",
    "\n",
    "\n",
    "def smiles_decoder(onehot):\n",
    "    smi = ''\n",
    "    onehot = onehot.argmax( axis=-1 )\n",
    "    for i in onehot:\n",
    "        smi += index2smi[i]\n",
    "    return smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!C[C@@]1(C(=O)C=C(O1)C(=O)[O-])c2ccccc2                                                             '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smiles_decoder(smiles_to_onehot(full_smiles_as_list[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### shape(56, 100, 34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('smallsmiles.txt') as f:\n",
    "    small_smiles_as_list = f.readlines()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57, 100, 35)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [smiles_to_onehot(x) for x in small_smiles_as_list]\n",
    "X = np.array(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### shape(115936, 100, 34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115936, 100, 36)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all = [smiles_to_onehot(x) for x in full_smiles_as_list]\n",
    "X_all = np.array(X_all)\n",
    "X_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 100, 36)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X_all[:10000]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model of the encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possible improvements <br>\n",
    "- more lstm layers <br>\n",
    "- lstm layer larger output dim <br>\n",
    "- to avoid posteior collapse problem give less weight to KL loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 LSTM layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input = Input(shape=input_dim)\n",
    "lstm = LSTM(inter_dim, return_sequences=True)(x_input)\n",
    "lstm_inter = LSTM(inter_dim)(lstm)\n",
    "z_mean = Dense(latent_dim)(lstm_inter)\n",
    "z_var = Dense(latent_dim)(lstm_inter)\n",
    "\n",
    "z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_var])\n",
    "encoder = Model(x_input, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input = Input(shape=input_dim)\n",
    "h = Convolution1D(9, 9, activation = 'relu', name='conv_1')(x_input)\n",
    "h = Convolution1D(9, 9, activation = 'relu', name='conv_2')(h)\n",
    "h = Convolution1D(10, 11, activation = 'relu', name='conv_3')(h)\n",
    "h = Flatten(name='flatten_1')(h)\n",
    "h = Dense(435, activation = 'relu', name='dense_1')(h)\n",
    "\n",
    "z_mean = Dense(latent_dim, name='z_mean', activation = 'linear')(h)\n",
    "z_var = Dense(latent_dim, name='z_log_var', activation = 'linear')(h)\n",
    "\n",
    "z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_var])\n",
    "encoder = Model(x_input, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input = Input(shape=input_dim)\n",
    "lstm = LSTM(64)(x_input)\n",
    "z_mean = Dense(latent_dim)(lstm)\n",
    "z_var = Dense(latent_dim)(lstm)\n",
    "\n",
    "z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_var])\n",
    "encoder = Model(x_input, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model of the decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 LSTM Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "repeated = RepeatVector(max_smiles_len)(latent_inputs)\n",
    "hidden_lstm = LSTM(inter_dim, return_sequences=True)(repeated)\n",
    "hidden_lstm = LSTM(inter_dim, return_sequences=True)(hidden_lstm)\n",
    "hidden_lstm = LSTM(inter_dim, return_sequences=True)(hidden_lstm)\n",
    "x_2 = TimeDistributed(Dense(num_smiles_chars, activation='softmax'), name='decoded_mean')(hidden_lstm)\n",
    "\n",
    "decoder = Model(latent_inputs, x_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 GRU layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "h = Dense(latent_dim, name='latent_input', activation = 'relu')(latent_inputs)\n",
    "h = RepeatVector(max_smiles_len, name='repeat_vector')(h)\n",
    "h = GRU(488, return_sequences = True, name='gru_1')(h)\n",
    "h = GRU(488, return_sequences = True, name='gru_2')(h)\n",
    "h = GRU(488, return_sequences = True, name='gru_3')(h)\n",
    "x_2 = TimeDistributed(Dense(num_smiles_chars, activation='softmax'), name='decoded_mean')(h)\n",
    "\n",
    "decoder = Model(latent_inputs, x_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SImple 1 lstm decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "repeated = RepeatVector(max_smiles_len)(latent_inputs)\n",
    "hidden_lstm = LSTM(inter_dim, return_sequences=True)(repeated)\n",
    "x_2 = TimeDistributed(Dense(num_smiles_chars, activation='softmax'), name='decoded_mean')(repeated)\n",
    "\n",
    "decoder = Model(latent_inputs, x_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(x, x_decoded):\n",
    "    x = K.flatten(x)\n",
    "    x_decoded = K.flatten(x_decoded)\n",
    "    recon = max_smiles_len * objectives.binary_crossentropy(x, x_decoded)\n",
    "\n",
    "    \n",
    "    kl = 0.5 * K.sum(K.exp(z_var) + K.square(z_mean) - 1. - z_var,axis = -1)\n",
    "    #kl *= 0.1\n",
    "    return recon + kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_loss(x, x_new):\n",
    "    #xent_loss = objectives.mse(x, x_new)\n",
    "    kl_loss = - 0.5 * K.mean(1 + z_var - K.square(z_mean) - K.exp(z_var))\n",
    "    # loss = kl_loss + xent_loss\n",
    "    return kl_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder.compile(loss=MSE, optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.zeros((10000,292))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " 1400/10000 [===>..........................] - ETA: 2:10 - loss: 0.0109"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-33bb9695dc58>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdecoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3740\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3742\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m     \"\"\"\n\u001b[1;32m-> 1081\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1121\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "decoder.fit(Y, X, epochs=1, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = np.zeros((3,292))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = decoder.predict(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 100, 35)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoder.compile(loss=calculate_loss, optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": " Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node conv_1_1/convolution (defined at C:\\Users\\ivani\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1751) ]] [Op:__inference_keras_scratch_graph_15343]\n\nFunction call stack:\nkeras_scratch_graph\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-a86eb6db157f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3740\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3742\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m     \"\"\"\n\u001b[1;32m-> 1081\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1121\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node conv_1_1/convolution (defined at C:\\Users\\ivani\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1751) ]] [Op:__inference_keras_scratch_graph_15343]\n\nFunction call stack:\nkeras_scratch_graph\n"
     ]
    }
   ],
   "source": [
    "encoder.fit(X, X, epochs=10, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = X[0:1]\n",
    "X1 = np.reshape(X1, (1,100,57))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-8.1301773e-01, -2.6299402e-01, -9.8160648e-01, -1.2278748e+00,\n",
       "        -1.1572304e+00, -1.5604430e+00, -1.3140545e+00, -7.6917696e-01,\n",
       "        -2.4372327e+00,  1.0624061e+00, -3.0992565e-01,  8.3419043e-01,\n",
       "         5.6062818e-01, -1.3172098e-01, -9.5717466e-01, -2.1324940e+00,\n",
       "         5.0561869e-01,  2.7011657e-01,  5.0852150e-01, -1.7143270e+00,\n",
       "         8.7156326e-01,  7.9136580e-01,  2.8402200e-01,  1.1757556e+00,\n",
       "        -6.0712612e-01,  2.3732959e-01,  1.5342817e+00,  8.8119239e-01,\n",
       "         1.3047813e+00, -7.7862233e-01, -1.4512120e-03,  1.3836908e-01,\n",
       "        -1.2058165e+00, -1.8850985e+00, -7.6009864e-01, -1.7057220e+00,\n",
       "        -1.0867665e+00, -1.8097383e+00,  1.2657901e+00, -2.4245261e-01,\n",
       "         1.1391633e+00,  5.5728078e-01, -1.2521151e-01,  3.1110209e-01,\n",
       "         1.3163338e+00,  2.4253933e+00,  1.1826134e+00,  1.9561082e+00,\n",
       "         9.5373905e-01, -4.7003338e-01,  1.5187393e+00, -1.9416742e-01,\n",
       "        -3.8858828e-01,  3.5764900e-01, -8.0885172e-01,  1.9086223e+00,\n",
       "        -1.6275990e+00, -2.9471168e-01,  2.0323863e+00,  4.6870928e-02,\n",
       "         2.3210883e-01,  1.2727907e+00,  2.7060246e-01, -1.9542056e+00]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = encoder.predict(X1)\n",
    "vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Compile VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = decoder(encoder(x_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = Model(x_input,outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop, Adam\n",
    "opt=Adam(lr=0.005)\n",
    "vae.compile(loss=calculate_loss, optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(filepath = 'model.hdf5',\n",
    "                               verbose = 1,\n",
    "                               save_best_only = True)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss',\n",
    "                              factor = 0.2,\n",
    "                              patience = 3,\n",
    "                              min_lr = 0.001)\n",
    "h = History()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 104342 samples, validate on 11594 samples\n",
      "Epoch 1/50\n",
      "104342/104342 [==============================] - 2597s 25ms/step - loss: 7.1323 - val_loss: 5.3990\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 5.39896, saving model to model.hdf5\n",
      "Epoch 2/50\n",
      "104342/104342 [==============================] - 2591s 25ms/step - loss: 5.2466 - val_loss: 5.3916\n",
      "\n",
      "Epoch 00002: val_loss improved from 5.39896 to 5.39161, saving model to model.hdf5\n",
      "Epoch 3/50\n",
      "104342/104342 [==============================] - 2590s 25ms/step - loss: 5.2478 - val_loss: 5.3933\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 5.39161\n",
      "Epoch 4/50\n",
      "104342/104342 [==============================] - 2588s 25ms/step - loss: 5.2465 - val_loss: 5.3998\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 5.39161\n",
      "Epoch 5/50\n",
      "104342/104342 [==============================] - 2590s 25ms/step - loss: 5.3282 - val_loss: 5.4629\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 5.39161\n",
      "Epoch 6/50\n",
      "104342/104342 [==============================] - 2589s 25ms/step - loss: 5.2513 - val_loss: 5.3963\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 5.39161\n",
      "Epoch 7/50\n",
      "104342/104342 [==============================] - 2589s 25ms/step - loss: 5.2547 - val_loss: 5.4021\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 5.39161\n",
      "Epoch 8/50\n",
      "104342/104342 [==============================] - 2589s 25ms/step - loss: 5.2476 - val_loss: 5.4029\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 5.39161\n",
      "Epoch 9/50\n",
      "104342/104342 [==============================] - 2587s 25ms/step - loss: 5.2764 - val_loss: 5.3930\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 5.39161\n",
      "Epoch 10/50\n",
      "104342/104342 [==============================] - 2589s 25ms/step - loss: 5.2471 - val_loss: 5.4208\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 5.39161\n",
      "Epoch 11/50\n",
      "104342/104342 [==============================] - 2589s 25ms/step - loss: 5.2471 - val_loss: 5.3906\n",
      "\n",
      "Epoch 00011: val_loss improved from 5.39161 to 5.39063, saving model to model.hdf5\n",
      "Epoch 12/50\n",
      "104342/104342 [==============================] - 2588s 25ms/step - loss: 5.2448 - val_loss: 5.3956\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 5.39063\n",
      "Epoch 13/50\n",
      "104342/104342 [==============================] - 2588s 25ms/step - loss: 5.2610 - val_loss: 5.4020\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 5.39063\n",
      "Epoch 14/50\n",
      "104342/104342 [==============================] - 2588s 25ms/step - loss: 5.2760 - val_loss: 5.3931\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 5.39063\n",
      "Epoch 15/50\n",
      "104342/104342 [==============================] - 2587s 25ms/step - loss: 5.2539 - val_loss: 5.3961\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 5.39063\n",
      "Epoch 16/50\n",
      "104342/104342 [==============================] - 2585s 25ms/step - loss: 5.2537 - val_loss: 5.3937\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 5.39063\n",
      "Epoch 17/50\n",
      "104342/104342 [==============================] - 2584s 25ms/step - loss: 5.2465 - val_loss: 5.4547\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 5.39063\n",
      "Epoch 18/50\n",
      "104342/104342 [==============================] - 2586s 25ms/step - loss: 5.2469 - val_loss: 5.4158\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 5.39063\n",
      "Epoch 19/50\n",
      "104342/104342 [==============================] - 2586s 25ms/step - loss: 5.2653 - val_loss: 5.3957\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 5.39063\n",
      "Epoch 20/50\n",
      "104342/104342 [==============================] - 2585s 25ms/step - loss: 5.2725 - val_loss: 5.3924\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 5.39063\n",
      "Epoch 21/50\n",
      "104342/104342 [==============================] - 2590s 25ms/step - loss: 5.2494 - val_loss: 5.3924\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 5.39063\n",
      "Epoch 22/50\n",
      "104342/104342 [==============================] - 2590s 25ms/step - loss: 5.2587 - val_loss: 5.5186\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 5.39063\n",
      "Epoch 23/50\n",
      "104342/104342 [==============================] - 2590s 25ms/step - loss: 5.2456 - val_loss: 5.3911\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 5.39063\n",
      "Epoch 24/50\n",
      "104300/104342 [============================>.] - ETA: 1s - loss: 5.2465"
     ]
    }
   ],
   "source": [
    "vae.fit(X,X, epochs=50, shuffle = True, batch_size=100,callbacks = [h, checkpointer, reduce_lr], validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vae.joblib']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(vae,'vae.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x20b80912240>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(h.history[\"loss\"], label=\"Loss\")\n",
    "plt.plot(h.history[\"val_loss\"], label=\"Val_Loss\")\n",
    "plt.yscale(\"log\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = X[-10:]\n",
    "X1 = np.reshape(X1, (10,100,36))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = vae.predict(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!C1ccccccc1cCCccccccccccccccccccccccccccCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "!C1ccccccc1cCCccccccccccccccccccccccccccCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "!C1ccccccc1cCCccccccccccccccccccccccccccCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "!C1ccccccc1cCCccccccccccccccccccccccccccCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "!C1ccccccc1cCCccccccccccccccccccccccccccCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "!C1ccccccc1cCCccccccccccccccccccccccccccCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "!C1ccccccc1cCCccccccccccccccccccccccccccCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "!C1ccccccc1cCCcccccccccccccccccccccccccCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "!C1ccccccc1cCCccccccccccccccccccccccccccCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "!C1ccccccc1cCCccccccccccccccccccccccccccCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n"
     ]
    }
   ],
   "source": [
    "for ind in np.arange(0,predicted.shape[0]):\n",
    "    print(smiles_decoder(predicted[ind]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!Cc1cccnc1NC(=O)c2ccc3c(c2)sc(n3)N                                                                  '"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smiles_decoder(X1[-10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5f = h5py.File('smiles_50k.h5', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['table']>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5f.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = h5f['table']['axis0']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
